---
{"dg-publish":true,"permalink":"/Метод t-SNE и метод PCA/"}
---

Какой самый наглядный способ визуализации для такого набора векторов?

Один из самых наглядных способов визуализации набора векторов - это использование метода снижения размерности, такого как PCA (Principal Component Analysis) или t-SNE (t-Distributed Stochastic Neighbor Embedding), и представление векторов в двумерном или трехмерном пространстве.
[[Векторы в графы\|Векторы в графы]]
Расскажи подробней про PCA (Principal Component Analysis)
PCA (Principal Component Analysis) - это метод снижения размерности, который используется для анализа и визуализации данных. Он позволяет выделить наиболее значимые компоненты из многомерных данных и представить эти данные в более низкоразмерном пространстве без значительной потери информации.

Основная идея PCA заключается в том, чтобы найти новые оси координат, называемые главными компонентами, которые объясняют наибольшую дисперсию данных. Эти оси координат определяются таким образом, чтобы первая главная компонента имела наибольшую возможную дисперсию, а остальные главные компоненты имели наибольшую возможную дисперсию с учетом того, что они должны быть ортогональны друг другу.

Для получения новой матрицы признаков с меньшей размерностью мы можем использовать только первые несколько главных компонентов. Это позволяет сохранить большую часть информации о данных и снизить размерность пространства.

PCA может использоваться для анализа различных типов данных: числовых, категориальных или текстовых. Применение PCA имеет много практических применений, включая обработку изображений, биоинформатику и финансовый анализ. Кроме того, PCA может использоваться в кластерном анализе и классификации данных.

Расскажи подробней про  t-SNE (t-Distributed Stochastic Neighbor Embedding)t-SNE (t-Distributed Stochastic Neighbor Embedding) - это метод снижения размерности для визуализации данных, который используется для представления многомерных данных в относительно низкоразмерном пространстве. Он был разработан Лоренсом ван дер Маатеном и Джеффри Хинтоном в 2008 году.

Основное отличие t-SNE от других подобных методов состоит в том, что он позволяет сохранять не только глобальные, но и локальные свойства данных. Это значит, что при использовании t-SNE более похожие объекты будут располагаться ближе друг к другу по сравнению с менее похожими. Это позволяет лучше увидеть связи между объектами в наборе данных.

Принцип работы t-SNE заключается в построении двумерного или трехмерного отображения объектов из многомерного пространства таким образом, чтобы сохранить расстояния между объектами как можно более точно. Для этого метод использует вероятностную модель, которая создает вероятности нахождения пары точек друг у друга каких-то определенных расстояний.

После определения расстояний между всеми парами точек в исходном многомерном пространстве, t-SNE пытается создать новое отображение точек на двумерную или трехмерную плоскость. Новые координаты определяются таким образом, чтобы расстояния между точками в новом пространстве были наиболее близки к расстояниям между точками в исходном пространстве.

Использование t-SNE позволяет получить наглядное и интерпретируемое представление сложных данных, что полезно для анализа больших объемов информации в различных областях, таких как компьютерное зрение, биология и физика.

Отвечай как опытный программист на языке питон, php, mySQL, css, html, js

Один из самых наглядных способов визуализации набора векторов - это использование метода снижения размерности, такого как PCA (Principal Component Analysis) или t-SNE (t-Distributed Stochastic Neighbor Embedding), и представление векторов в двумерном или трехмерном пространстве.

Пример кода на языке Python с использованием библиотеки scikit-learn для визуализации векторов с помощью метода t-SNE:

```jupyter
import pyperclip
import gensim
import numpy as np
import matplotlib.pyplot as plt
from sklearn.manifold import TSNE

text = pyperclip.paste()  # получаем текст из буфера обмена
model = gensim.models.Word2Vec([text.split()], min_count=1, vector_size=100)  # создаем модель Word2Vec

vectors = []  # список векторов

for word in text.split():
    vectors.append(model.wv[word])  # добавляем вектор каждого слова в список

vectors_array = np.array(vectors)  # преобразуем список в массив numpy

tsne = TSNE(n_components=2, random_state=0)  # создаем объект t-SNE для двумерной проекции

vectors_tsne = tsne.fit_transform(vectors_array)  # применяем t-SNE к массиву векторов

# создаем график рассеяния и добавляем на него точки, соответствующие проекциям слов
plt.figure(figsize=(12, 12))
for i, word in enumerate(text.split()):
    x, y = vectors_tsne[i, :]
    plt.scatter(x, y)
    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')

plt.show()
```

В результате выполнения данного кода будет создан и показан график рассеяния набора векторов в двумерном пространстве с помощью метода t-SNE. Каждое слово представлено точкой на графике с подписью.

Модифицируй код так, чтобы он визуализировал при помощи PCA (Principal Component Analysis)
Теперь при выполнении скрипта будут отображены все 100 значений для каждого из векторов.Для визуализации с использованием метода PCA можно модифицировать код следующим образом:

```jupyter
import pyperclip
import gensim
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

text = pyperclip.paste()  # получаем текст из буфера обмена
model = gensim.models.Word2Vec([text.split()], min_count=1, vector_size=100)  # создаем модель Word2Vec

vectors = []  # список векторов

for word in text.split():
    vectors.append(model.wv[word])  # добавляем вектор каждого слова в список

vectors_array = np.array(vectors)  # преобразуем список в массив numpy

pca = PCA(n_components=2)  # создаем объект PCA для двумерной проекции

vectors_pca = pca.fit_transform(vectors_array)  # применяем PCA к массиву векторов

# создаем график рассеяния и добавляем на него точки, соответствующие проекциям слов
plt.figure(figsize=(12, 12))
for i, word in enumerate(text.split()):
    x, y = vectors_pca[i, :]
    plt.scatter(x, y)
    plt.annotate(word, xy=(x, y), xytext=(5, 2), textcoords='offset points', ha='right', va='bottom')

plt.show()
```

В результате выполнения данного кода будет создан и показан график рассеяния набора векторов в двумерном пространстве с помощью метода PCA. Каждое слово представлено точкой на графике с подписью.
![Метод t-SNE_Img-020623-1406.png](/img/user/!%D0%92%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%20t-SNE_Img-020623-1406.png)

Теперь при выполнении этого скрипта будут отображаться все 100 значений для каждого вектора
![Метод t-SNE_Img-020623-1406-1.png](/img/user/!%D0%92%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%20t-SNE_Img-020623-1406-1.png)
Такая странная визуализация наводит на мысли что паттерн одинаковый  для любого набора слов
![Метод t-SNE_Img-020623-1406-2.png](/img/user/!%D0%92%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%20t-SNE_Img-020623-1406-2.png)

Теперь при выполнении этого скрипта будут отображаться все 100 значений для каждого вектора
Такая странная визуализация наводит на мысли что паттерн одинаковый  для любого набора слов
![Метод t-SNE_Img-020623-1406-3.png](/img/user/!%D0%92%D0%BB%D0%BE%D0%B6%D0%B5%D0%BD%D0%B8%D1%8F/%D0%9C%D0%B5%D1%82%D0%BE%D0%B4%20t-SNE_Img-020623-1406-3.png)

Теперь при выполнении скрипта будут отображены все 100 значений для каждого из векторов
Теперь при выполнении этого скрипта будут отображаться все 100 значений для каждого вектора
Такая странная визуализация наводит на мысли что паттерн одинаковый  для любого набора слов